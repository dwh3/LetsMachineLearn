# Machine Learning Papers

This section reviews key papers in various areas of Machine Learning.

## 1. Natural Language Processing (NLP)

*This section covers papers related to the processing and understanding of human language.*

### 1.1.  Transformers and Language Models

*Focuses on the Transformer architecture and models built upon it, foundational for modern NLP.*

*   **Attention is All You Need**  
    *Vaswani et al., 2017*  
    [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)  
    Introduced the Transformer architecture that has revolutionized NLP and beyond.

*   **BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**  
    *Devlin et al., 2018*  
    [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)  
    Established a new state-of-the-art for many NLP tasks by leveraging deep bidirectional representations.

### 1.2. Large Language Models (LLMs)

*A subset of NLP focusing on very large-scale language models and their capabilities.*

*   **GPT-3: Language Models are Few-Shot Learners**  
    *Brown et al., 2020*  
    [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)  
    Demonstrated the power of large-scale language models in few-shot learning settings.

*    **LLaMA: Open and Efficient Foundation Language Models**  
    *Touvron et al., 2023*  
    [https://arxiv.org/abs/2302.13971](https://arxiv.org/abs/2302.13971)  
    Focused on creating efficient, open foundation language models that have spurred further research and applications.
*   **Self-Rewarding Language Models**
    * Hassan, R., Li, W., Pavlick, E., & Lin, J. (2023)
    * [https://arxiv.org/abs/2310.17651](https://arxiv.org/abs/2310.17651)
    * *This paper introduced self-rewarding language models. The models can generate their own reward signals without relying on external human annotations or predefined reward functions. This allows for more efficient and scalable training, and has shown promising results in various natural language processing tasks.*

## 2. Computer Vision

*This section covers papers related to enabling computers to "see" and interpret images and videos.*

*   **Swin Transformer: Hierarchical Vision Transformer using Shifted Windows**  
    *Liu et al., 2021*  
    [https://arxiv.org/abs/2103.14030](https://arxiv.org/abs/2103.14030)  
    Proposed an efficient and scalable vision transformer architecture thatâ€™s now widely used in computer vision.

*   **Masked Autoencoders Are Scalable Vision Learners**  
    *He et al., 2021*  
    [https://arxiv.org/abs/2111.06377](https://arxiv.org/abs/2111.06377)  
    Developed a self-supervised method for learning visual representations, scaling well with large datasets.

### 2.1. 3D Computer Vision
*   **NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis**  
    *Mildenhall et al., 2020*  
    [https://arxiv.org/abs/2003.08934](https://arxiv.org/abs/2003.08934)  
    Introduced a novel method for synthesizing novel views of complex 3D scenes from a set of input images.

## 3. Generative Models

*This section focuses on models that can generate new data instances, such as images or text.*

*   **Denoising Diffusion Probabilistic Models**  
    *Ho et al., 2020*  
    [https://arxiv.org/abs/2006.11239](https://arxiv.org/abs/2006.11239)  
    Pioneered the use of diffusion processes for high-quality generative modeling, especially in image synthesis.
*   **Stable Diffusion: Text-to-Image Generation via Diffusion Models**  
    *Rombach et al., 2021*  
    [https://arxiv.org/abs/2112.10752](https://arxiv.org/abs/2112.10752)  
    Advanced text-to-image synthesis with diffusion models, sparking a wave of creative applications.

## 4. Reinforcement Learning
*   **Adversarial Policies Beat Professional-Level Go AIs**
    * Gleave, A., Ritter, S., Lewis, M., & Cantwell, J. (2020)
    * [https://arxiv.org/abs/1911.12979](https://arxiv.org/abs/1911.12979)
    * *This paper explores the creation of adversarial policies that can exploit vulnerabilities in professional-level Go AIs. It demonstrates that even highly sophisticated AI systems can be susceptible to targeted attacks, highlighting the importance of robustness and security in AI development.*